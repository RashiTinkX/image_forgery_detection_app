{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a58a049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\zzzri\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-08 15:24:08.048 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\zzzri\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import numpy as np\n",
    "import cv2\n",
    "import requests\n",
    "from skimage import color\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import pytesseract\n",
    "from langdetect import detect\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "# Set the path to the Tesseract executable\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "def load_pretrained_cnn_model():\n",
    "    # Load pre-trained VGG16 model\n",
    "    model = VGG16(weights='imagenet', input_shape=(224, 224, 3))  # Add input_shape argument\n",
    "    return model\n",
    "\n",
    "def predict_image_class(model, image_path):\n",
    "    # Load and preprocess the image for VGG16\n",
    "    img = image.load_img(image_path, target_size=(224, 224))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = preprocess_input(img_array)\n",
    "\n",
    "    # Get predictions for the image\n",
    "    predictions = model.predict(img_array)\n",
    "\n",
    "    # Decode and print the top-3 predicted classes\n",
    "    decoded_predictions = decode_predictions(predictions, top=3)[0]\n",
    "    \n",
    "    if not decoded_predictions:\n",
    "        st.write(\"No predictions available.\")\n",
    "        return None, None\n",
    "    \n",
    "    label, confidence = decoded_predictions[0][1], decoded_predictions[0][2]\n",
    "    st.write(f\"{label}: {confidence:.2f}\")\n",
    "    return label, confidence\n",
    "\n",
    "def retrieve_image(image_url):\n",
    "    response = requests.get(image_url)\n",
    "    image = np.asarray(bytearray(response.content), dtype=\"uint8\")\n",
    "    image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "    return image\n",
    "\n",
    "def perform_error_level_analysis(image):\n",
    "    # Calculate the error level of the image\n",
    "    error_map = np.abs(np.diff(image.astype(int), axis=2)).sum(axis=2)\n",
    "    error_level = error_map.mean()\n",
    "    return error_level\n",
    "\n",
    "def perform_sift_feature_extraction(image):\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(gray_image, None)\n",
    "    return keypoints, descriptors\n",
    "\n",
    "def display_image(image, title=\"Image\"):\n",
    "    plt.figure(figsize=(7, 7))  # Adjust the figure size as needed\n",
    "    plt.imshow(image)\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def display_image_with_regions(image, regions, title=\"Tampered Image with Regions\"):\n",
    "    image_copy = image.copy()\n",
    "    for i, region in enumerate(regions):\n",
    "        x, y, w, h = region\n",
    "        cv2.rectangle(image_copy, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "        cv2.putText(image_copy, f\"Region {i + 1}\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
    "    plt.figure(figsize=(7, 7))  # Adjust the figure size as needed\n",
    "    plt.imshow(cv2.cvtColor(image_copy, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    st.pyplot()\n",
    "\n",
    "def detect_tampered_regions(image):\n",
    "    image_array = np.array(image)\n",
    "    if len(image_array.shape) == 2:\n",
    "        gray_image = image_array\n",
    "    else:\n",
    "        gray_image = color.rgb2gray(image_array)\n",
    "    gray_image = (gray_image * 255).astype(np.uint8)\n",
    "    _, binary = cv2.threshold(gray_image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    contours, _ = cv2.findContours(binary.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    tampered_regions = []\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area > 100:  # Adjust the threshold as per your needs\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            tampered_regions.append((x, y, w, h))\n",
    "    return tampered_regions\n",
    "\n",
    "def analyze_metadata(image):\n",
    "    info = {}\n",
    "    height, width = image.shape[:2]\n",
    "    info['ImageWidth'] = width\n",
    "    info['ImageHeight'] = height\n",
    "    return info\n",
    "\n",
    "def detect_scribbling(image):\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    _, thresholded_image = cv2.threshold(gray_image, 0, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "    contours, _ = cv2.findContours(thresholded_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    total_area = 0\n",
    "    for contour in contours:\n",
    "        total_area += cv2.contourArea(contour)\n",
    "        image_area = image.shape[0] * image.shape[1]\n",
    "        area_percentage = total_area / image_area\n",
    "        scribbling_threshold = 0.1  # Adjust this threshold value as needed\n",
    "        if area_percentage > scribbling_threshold:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "def detect_digital_forgery(image):\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    edges = cv2.Canny(gray_image, 100, 200)\n",
    "    dilated_edges = cv2.dilate(edges, None)\n",
    "    contours, _ = cv2.findContours(dilated_edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    for contour in contours:\n",
    "        perimeter = cv2.arcLength(contour, True)\n",
    "        approx_polygon = cv2.approxPolyDP(contour, 0.02 * perimeter, True)\n",
    "        if len(approx_polygon) < 5:\n",
    "            return True\n",
    "\n",
    "        return False\n",
    "\n",
    "def detect_data_manipulation(image):\n",
    "    mean_intensity = np.mean(image)\n",
    "    std_intensity = np.std(image)\n",
    "    intensity_threshold = 50  # Adjust this threshold value as needed\n",
    "    if std_intensity > intensity_threshold:\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "def detect_whitener(image):\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    histogram = cv2.calcHist([gray_image], [0], None, [256], [0, 256])\n",
    "    whitened_pixels_percentage = histogram[-1] / np.sum(histogram)\n",
    "    whitening_threshold = 0.1  # Adjust this threshold value as needed\n",
    "    if whitened_pixels_percentage > whitening_threshold:\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "def generate_noise_map(image):\n",
    "    image_array = np.array(image)\n",
    "    if len(image_array.shape) == 2:\n",
    "        noise_map = np.copy(image_array)\n",
    "    else:\n",
    "        gray_image = cv2.cvtColor(image_array, cv2.COLOR_RGB2GRAY)\n",
    "        blurred_gray_image = cv2.GaussianBlur(gray_image, (11, 11), 0)\n",
    "        noise_map = cv2.absdiff(gray_image, blurred_gray_image)\n",
    "        return noise_map\n",
    "\n",
    "def perform_ocr(image):\n",
    "    text = pytesseract.image_to_string(image)\n",
    "    return text\n",
    "\n",
    "def language_and_font_analysis(image):\n",
    "    text_representation = pytesseract.image_to_string(image)\n",
    "    language = detect(text_representation)\n",
    "    return language\n",
    "\n",
    "def false_positive_reduction(tampered_regions, noise_map):\n",
    "    filtered_regions = []\n",
    "    for region in tampered_regions:\n",
    "        x, y, w, h = region\n",
    "        region_noise = noise_map[y:y+h, x:x+w]\n",
    "        region_noise_pixels = np.count_nonzero(region_noise)\n",
    "        if region_noise_pixels / (region_noise.shape[0] * region_noise.shape[1]) > 0.1:\n",
    "            filtered_regions.append(region)\n",
    "\n",
    "    return filtered_regions\n",
    "\n",
    "def visualize_noise_map(image, noise_map):\n",
    "    noise_map_rgb = cv2.cvtColor(noise_map, cv2.COLOR_GRAY2RGB)\n",
    "    alpha = 0.6\n",
    "    output = cv2.addWeighted(np.array(image), 1-alpha, noise_map_rgb, alpha, 0)\n",
    "    display_image(output)\n",
    "\n",
    "def compare_text(genuine_text, tampered_text):\n",
    "    seq_matcher = SequenceMatcher(None, genuine_text, tampered_text)\n",
    "    differences = list(seq_matcher.get_opcodes())\n",
    "    for tag, i1, i2, j1, j2 in differences:\n",
    "        if tag in ['insert', 'replace']:\n",
    "            st.write(f'\\033[1mTampered Text Differs at Position [{j1}:{j2}]: \"{tampered_text[j1:j2]}\"\\033[0m')\n",
    "\n",
    "def process_tampered_image(tampered_image_url):\n",
    "    # Load pre-trained CNN model\n",
    "    cnn_model = load_pretrained_cnn_model()\n",
    "\n",
    "    # Retrieve the tampered image\n",
    "    tampered_image = retrieve_image(tampered_image_url)\n",
    "\n",
    "    # Save the tampered image for CNN processing\n",
    "    cnn_image_path = \"tampered_image_for_cnn.jpg\"\n",
    "    cv2.imwrite(cnn_image_path, tampered_image)\n",
    "    predicted_label, confidence = predict_image_class(cnn_model, cnn_image_path)\n",
    "    st.write(f\"\\033[1mPredicted class: {predicted_label}, Confidence: {confidence:.2f}\\033[0m\")\n",
    "\n",
    "    # Perform error level analysis on the tampered image\n",
    "    tampered_error_level = perform_error_level_analysis(np.array(tampered_image))\n",
    "\n",
    "    tampered_keypoints, tampered_descriptors = perform_sift_feature_extraction(np.array(tampered_image))\n",
    "    tampered_regions = detect_tampered_regions(tampered_image)\n",
    "\n",
    "    metadata_tampered = analyze_metadata(tampered_image)\n",
    "\n",
    "    noise_map = generate_noise_map(tampered_image)\n",
    "\n",
    "    text_tampered = perform_ocr(tampered_image)\n",
    "\n",
    "    language_tampered = language_and_font_analysis(tampered_image)\n",
    "\n",
    "    tampered_regions_filtered = false_positive_reduction(tampered_regions, noise_map)\n",
    "\n",
    "    # Display the tampered image with regions\n",
    "    display_image_with_regions(tampered_image, tampered_regions_filtered)\n",
    "\n",
    "    st.write(\"\\033[1mError level of tampered image:\\033[0m\", tampered_error_level)\n",
    "    tampered_image_types = []\n",
    "    scribbling_regions = detect_scribbling(tampered_image)\n",
    "    digital_forgery_regions = detect_digital_forgery(tampered_image)\n",
    "    data_manipulation_regions = detect_data_manipulation(tampered_image)\n",
    "    whitener_regions = detect_whitener(tampered_image)\n",
    "\n",
    "    if scribbling_regions:\n",
    "        tampered_image_types.append(\"Scribbling/Overwriting Forgery\")\n",
    "        st.write(\"\\033[1mScribbling/Overwriting Forgery detected at regions:\\033[0m\", scribbling_regions)\n",
    "    if digital_forgery_regions:\n",
    "        tampered_image_types.append(\"Digital Forgery\")\n",
    "        st.write(\"\\033[1mDigital Forgery detected at regions:\\033[0m\", digital_forgery_regions)\n",
    "    if data_manipulation_regions:\n",
    "        tampered_image_types.append(\"Data Manipulation Forgery\")\n",
    "        st.write(\"\\033[1mData Manipulation Forgery detected at regions:\\033[0m\", data_manipulation_regions)\n",
    "    if whitener_regions:\n",
    "        tampered_image_types.append(\"Whitener Forgery\")\n",
    "        st.write(\"\\033[1mWhitener Forgery detected at regions:\\033[0m\", whitener_regions)\n",
    "\n",
    "    # Classification based on forgery detection\n",
    "    if tampered_image_types:\n",
    "        st.write(\"\\033[1mClassification: Forged\\033[0m\")\n",
    "    else:\n",
    "        st.write(\"\\033[1mClassification: Genuine\\033[0m\")\n",
    "\n",
    "    # Predict the image class using the pre-trained CNN\n",
    "    predict_image_class(cnn_model, cnn_image_path)\n",
    "\n",
    "    # Display the tampered image with regions\n",
    "    for region in tampered_regions_filtered:\n",
    "        if isinstance(region, bool):  # Skip boolean values\n",
    "            continue\n",
    "        x, y, w, h = region\n",
    "        cv2.rectangle(tampered_image, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "\n",
    "    st.image(tampered_image, caption=\"Tampered Image\", use_column_width=True)\n",
    "    st.write(\"\\033[1mError level of tampered image:\\033[0m\", tampered_error_level)\n",
    "    st.write(\"\\033[1mNumber of keypoints in tampered image:\\033[0m\", len(tampered_keypoints))\n",
    "    st.write(\"\\033[1mMetadata of tampered image:\\033[0m\", metadata_tampered)\n",
    "    st.write(\"\\033[1mText detected in tampered image:\\033[0m\", text_tampered)\n",
    "    st.write(\"\\033[1mLanguage of tampered image:\\033[0m\", language_tampered)\n",
    "\n",
    "    visualize_noise_map(tampered_image, noise_map)\n",
    "\n",
    "# Create a Streamlit app\n",
    "st.title(\"Image Analysis App\")\n",
    "\n",
    "# Add a text input field for the user to enter the image URL\n",
    "image_url = st.text_input(\"Enter the image URL:\")\n",
    "\n",
    "# Check if the user has entered a valid URL\n",
    "if image_url:\n",
    "    # Process the tampered image using the provided URL\n",
    "    process_tampered_image(image_url)\n",
    "else:\n",
    "    st.write(\"Please enter a valid image URL.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f609ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
